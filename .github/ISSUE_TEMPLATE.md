---
title: Latest 15 Papers - May 15, 2025
labels: documentation
---
**Please check the [Github](https://github.com/pstAmbition/DailyArXiv) page for a better reading experience and more papers.**

## Agent
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Language Agents Mirror Human Causal Reasoning Biases. How Can We Help Them Think Like Scientists?](http://arxiv.org/abs/2505.09614v1)** | 2025-05-14 |  |
| **[Multi-Agent Reinforcement Learning Simulation for Environmental Policy Synthesis](http://arxiv.org/abs/2504.12777v2)** | 2025-05-14 | <details><summary>Publi...</summary><p>Published in AAMAS'25 Blue Sky Ideas Track</p></details> |
| **[Streaming Multi-agent Pathfinding](http://arxiv.org/abs/2505.09472v1)** | 2025-05-14 | <details><summary>to be...</summary><p>to be published in IJCAI2025</p></details> |
| **[Cognitive Insights and Stable Coalition Matching for Fostering Multi-Agent Cooperation](http://arxiv.org/abs/2405.18044v2)** | 2025-05-14 |  |
| **[The Influence of Human-inspired Agentic Sophistication in LLM-driven Strategic Reasoners](http://arxiv.org/abs/2505.09396v1)** | 2025-05-14 |  |
| **[Think Smart, Act SMARL! Analyzing Probabilistic Logic Shields for Multi-Agent Reinforcement Learning](http://arxiv.org/abs/2411.04867v2)** | 2025-05-14 | <details><summary>21 pa...</summary><p>21 pages, 16 figures, Earlier title: "Analyzing Probabilistic Logic Driven Safety in Multi-Agent Reinforcement Learning" (changed for specificity and clarity)</p></details> |
| **[Neural Brain: A Neuroscience-inspired Framework for Embodied Agents](http://arxiv.org/abs/2505.07634v2)** | 2025-05-14 | <details><summary>51 pa...</summary><p>51 pages, 17 figures, 9 tables</p></details> |
| **[UI-R1: Enhancing Efficient Action Prediction of GUI Agents by Reinforcement Learning](http://arxiv.org/abs/2503.21620v4)** | 2025-05-14 | Updated UI-R1-E-3B |
| **[Reproducibility Study of "Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents"](http://arxiv.org/abs/2505.09289v1)** | 2025-05-14 | 11 Tables, 9 Figures |
| **[Agent RL Scaling Law: Agent RL with Spontaneous Code Execution for Mathematical Problem Solving](http://arxiv.org/abs/2505.07773v2)** | 2025-05-14 |  |
| **[SALM: A Multi-Agent Framework for Language Model-Driven Social Network Simulation](http://arxiv.org/abs/2505.09081v1)** | 2025-05-14 |  |
| **[Towards Autonomous UAV Visual Object Search in City Space: Benchmark and Agentic Methodology](http://arxiv.org/abs/2505.08765v2)** | 2025-05-14 |  |
| **[Enhancing Aerial Combat Tactics through Hierarchical Multi-Agent Reinforcement Learning](http://arxiv.org/abs/2505.08995v1)** | 2025-05-13 | <details><summary>Publi...</summary><p>Published as journal chapter in Deep Learning Applications, Vol. 1, by Taylor & Francis</p></details> |
| **[CrashFixer: A crash resolution agent for the Linux kernel](http://arxiv.org/abs/2504.20412v2)** | 2025-05-13 |  |
| **[AI Hiring with LLMs: A Context-Aware and Explainable Multi-Agent Framework for Resume Screening](http://arxiv.org/abs/2504.02870v2)** | 2025-05-13 | <details><summary>Accep...</summary><p>Accepted by CVPR 2025 Workshop</p></details> |

## LLM
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Adversarial Suffix Filtering: a Defense Pipeline for LLMs](http://arxiv.org/abs/2505.09602v1)** | 2025-05-14 |  |
| **[How Hungry is AI? Benchmarking Energy, Water, and Carbon Footprint of LLM Inference](http://arxiv.org/abs/2505.09598v1)** | 2025-05-14 |  |
| **[Omni-R1: Do You Really Need Audio to Fine-Tune Your Audio LLM?](http://arxiv.org/abs/2505.09439v1)** | 2025-05-14 |  |
| **[SafePath: Conformal Prediction for Safe LLM-Based Autonomous Navigation](http://arxiv.org/abs/2505.09427v1)** | 2025-05-14 |  |
| **[The Influence of Human-inspired Agentic Sophistication in LLM-driven Strategic Reasoners](http://arxiv.org/abs/2505.09396v1)** | 2025-05-14 |  |
| **[What Features in Prompts Jailbreak LLMs? Investigating the Mechanisms Behind Attacks](http://arxiv.org/abs/2411.03343v2)** | 2025-05-14 |  |
| **[Statistical Modeling and Uncertainty Estimation of LLM Inference Systems](http://arxiv.org/abs/2505.09319v1)** | 2025-05-14 |  |
| **[Reproducibility Study of "Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents"](http://arxiv.org/abs/2505.09289v1)** | 2025-05-14 | 11 Tables, 9 Figures |
| **[Harden and Catch for Just-in-Time Assured LLM-Based Software Testing: Open Research Challenges](http://arxiv.org/abs/2504.16472v2)** | 2025-05-14 | <details><summary>To Ap...</summary><p>To Appear as keynote paper at FSE 2025</p></details> |
| **[LLM-based NLG Evaluation: Current Status and Challenges](http://arxiv.org/abs/2402.01383v3)** | 2025-05-14 |  |
| **[ELIS: Efficient LLM Iterative Scheduling System with Response Length Predictor](http://arxiv.org/abs/2505.09142v1)** | 2025-05-14 | <details><summary>13 pa...</summary><p>13 pages, 5 figures. Cloud-native LLM scheduling system with latency-aware inference optimization</p></details> |
| **[Oaken: Fast and Efficient LLM Serving with Online-Offline Hybrid KV Cache Quantization](http://arxiv.org/abs/2503.18599v2)** | 2025-05-14 | <details><summary>16 pa...</summary><p>16 pages, 14 figures, and 4 tables</p></details> |
| **[CEC-Zero: Chinese Error Correction Solution Based on LLM](http://arxiv.org/abs/2505.09082v1)** | 2025-05-14 |  |
| **[P-MMEval: A Parallel Multilingual Multitask Benchmark for Consistent Evaluation of LLMs](http://arxiv.org/abs/2411.09116v2)** | 2025-05-14 |  |
| **[Improving the Reliability of LLMs: Combining CoT, RAG, Self-Consistency, and Self-Verification](http://arxiv.org/abs/2505.09031v1)** | 2025-05-13 |  |

## Representation Learning
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Advancing Drug Discovery with Enhanced Chemical Understanding via Asymmetric Contrastive Multimodal Learning](http://arxiv.org/abs/2311.06456v6)** | 2025-05-14 | <details><summary>51 pa...</summary><p>51 pages, 19 figures, 11 tables</p></details> |
| **[DACAD: Domain Adaptation Contrastive Learning for Anomaly Detection in Multivariate Time Series](http://arxiv.org/abs/2404.11269v3)** | 2025-05-14 | <details><summary>11 pa...</summary><p>11 pages, 3 figures, 6 tables</p></details> |
| **[Unsupervised Multiview Contrastive Language-Image Joint Learning with Pseudo-Labeled Prompts Via Vision-Language Model for 3D/4D Facial Expression Recognition](http://arxiv.org/abs/2505.09336v1)** | 2025-05-14 |  |
| **[OLinear: A Linear Model for Time Series Forecasting in Orthogonally Transformed Domain](http://arxiv.org/abs/2505.08550v2)** | 2025-05-14 |  |
| **[Stable and Convexified Information Bottleneck Optimization via Symbolic Continuation and Entropy-Regularized Trajectories](http://arxiv.org/abs/2505.09239v1)** | 2025-05-14 | <details><summary>23 pa...</summary><p>23 pages, 11 figures, includes analytical proofs, sensitivity analysis (95% CI), and JAX-based open-source implementation available at: https://github.com/farukalpay/information-bottleneck-beta-optimization</p></details> |
| **[A Multi-Task Foundation Model for Wireless Channel Representation Using Contrastive and Masked Autoencoder Learning](http://arxiv.org/abs/2505.09160v1)** | 2025-05-14 |  |
| **[DyGSSM: Multi-view Dynamic Graph Embeddings with State Space Model Gradient Update](http://arxiv.org/abs/2505.09017v1)** | 2025-05-13 |  |
| **[Deep Representation Learning for Unsupervised Clustering of Myocardial Fiber Trajectories in Cardiac Diffusion Tensor Imaging](http://arxiv.org/abs/2504.01953v2)** | 2025-05-13 | <details><summary>10 pa...</summary><p>10 pages, 5 figures. An extended journal manuscript is in preparation</p></details> |
| **[No Other Representation Component Is Needed: Diffusion Transformers Can Provide Representation Guidance by Themselves](http://arxiv.org/abs/2505.02831v3)** | 2025-05-13 | <details><summary>Self-...</summary><p>Self-Representation Alignment for Diffusion Transformers. Code: https://github.com/vvvvvjdy/SRA</p></details> |
| **[Modeling Unseen Environments with Language-guided Composable Causal Components in Reinforcement Learning](http://arxiv.org/abs/2505.08361v1)** | 2025-05-13 | <details><summary>Publi...</summary><p>Published as a conference paper at ICLR 2025</p></details> |
| **[Transformer representation learning is necessary for dynamic multi-modal physiological data on small-cohort patients](http://arxiv.org/abs/2504.04120v3)** | 2025-05-13 |  |
| **[LLM Enhancers for GNNs: An Analysis from the Perspective of Causal Mechanism Identification](http://arxiv.org/abs/2505.08265v1)** | 2025-05-13 | <details><summary>Accep...</summary><p>Accepted by ICML 2025</p></details> |
| **[Training Strategies for Efficient Embodied Reasoning](http://arxiv.org/abs/2505.08243v1)** | 2025-05-13 |  |
| **[A Multi-scale Representation Learning Framework for Long-Term Time Series Forecasting](http://arxiv.org/abs/2505.08199v1)** | 2025-05-13 |  |
| **[Empowering Vision Transformers with Multi-Scale Causal Intervention for Long-Tailed Image Classification](http://arxiv.org/abs/2505.08173v1)** | 2025-05-13 |  |

## Multimodal Learning
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Advancing Drug Discovery with Enhanced Chemical Understanding via Asymmetric Contrastive Multimodal Learning](http://arxiv.org/abs/2311.06456v6)** | 2025-05-14 | <details><summary>51 pa...</summary><p>51 pages, 19 figures, 11 tables</p></details> |
| **[Decoupled Multimodal Prototypes for Visual Recognition with Missing Modalities](http://arxiv.org/abs/2505.08283v1)** | 2025-05-13 |  |
| **[SonicRAG : High Fidelity Sound Effects Synthesis Based on Retrival Augmented Generation](http://arxiv.org/abs/2505.03244v2)** | 2025-05-13 | 8 pages, 5 figures |
| **[MedualTime: A Dual-Adapter Language Model for Medical Time Series-Text Multimodal Learning](http://arxiv.org/abs/2406.06620v3)** | 2025-05-12 | <details><summary>9 pag...</summary><p>9 pages, 6 figure, 3 tables</p></details> |
| **[Beyond DAGs: A Latent Partial Causal Model for Multimodal Learning](http://arxiv.org/abs/2402.06223v2)** | 2025-05-12 |  |
| **[MMiC: Mitigating Modality Incompleteness in Clustered Federated Learning](http://arxiv.org/abs/2505.06911v1)** | 2025-05-11 | <details><summary>10 pa...</summary><p>10 pages, 10 figures, it's KDD'2025 under reviewing</p></details> |
| **[Batch Augmentation with Unimodal Fine-tuning for Multimodal Learning](http://arxiv.org/abs/2505.06592v1)** | 2025-05-10 |  |
| **[NSF-MAP: Neurosymbolic Multimodal Fusion for Robust and Interpretable Anomaly Prediction in Assembly Pipelines](http://arxiv.org/abs/2505.06333v1)** | 2025-05-09 | <details><summary>9 pag...</summary><p>9 pages, 7 figures, 2 tables, IJCAI 2025 (International Joint Conferences on Artificial Intelligence) Special Track on AI4Tech: AI Enabling Critical Technologies</p></details> |
| **[Multimodal Sentiment Analysis on CMU-MOSEI Dataset using Transformer-based Models](http://arxiv.org/abs/2505.06110v1)** | 2025-05-09 | <details><summary>6 pag...</summary><p>6 pages, 2 figures, 5 tables, and 19 references</p></details> |
| **[The Moon's Many Faces: A Single Unified Transformer for Multimodal Lunar Reconstruction](http://arxiv.org/abs/2505.05644v1)** | 2025-05-08 | 14pages |
| **[OpenVision: A Fully-Open, Cost-Effective Family of Advanced Vision Encoders for Multimodal Learning](http://arxiv.org/abs/2505.04601v1)** | 2025-05-07 |  |
| **[A Vision-Language Model for Focal Liver Lesion Classification](http://arxiv.org/abs/2505.03350v1)** | 2025-05-06 | <details><summary>9 pag...</summary><p>9 pages,4 figures, 4 tables,Innovation in Medicine and Healthcare Proceedings of 13th KES-InMed 2025</p></details> |
| **[The Multimodal Paradox: How Added and Missing Modalities Shape Bias and Performance in Multimodal AI](http://arxiv.org/abs/2505.03020v1)** | 2025-05-05 | <details><summary>CVPR ...</summary><p>CVPR 2025 Second Workshop on Responsible Generative AI</p></details> |
| **[Aggregation of Dependent Expert Distributions in Multimodal Variational Autoencoders](http://arxiv.org/abs/2505.01134v1)** | 2025-05-02 |  |
| **[Investigating Zero-Shot Diagnostic Pathology in Vision-Language Models with Efficient Prompt Design](http://arxiv.org/abs/2505.00134v1)** | 2025-04-30 |  |

